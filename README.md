

<h1 align="center"> Physical AI Lab </h1>

<div align="center">
<a href="https://pseudo-lab.com"><img src="https://img.shields.io/badge/PseudoLab-S11-3776AB" alt="PseudoLab"/></a>
<a href="https://discord.gg/EPurkHVtp2"><img src="https://img.shields.io/badge/Discord-BF40BF" alt="Discord Community"/></a>
<a href="https://github.com/Pseudo-Lab/PhyAI-Lab/stargazers"><img src="https://img.shields.io/github/stars/Pseudo-Lab/PhyAI-Lab" alt="Stars Badge"/></a>
<a href="https://github.com/Pseudo-Lab/PhyAI-Lab/network/members"><img src="https://img.shields.io/github/forks/Pseudo-Lab/PhyAI-Lab" alt="Forks Badge"/></a>
<a href="https://github.com/Pseudo-Lab/PhyAI-Lab/pulls"><img src="https://img.shields.io/github/issues-pr/Pseudo-Lab/PhyAI-Lab" alt="Pull Requests Badge"/></a>
<a href="https://github.com/Pseudo-Lab/PhyAI-Lab/issues"><img src="https://img.shields.io/github/issues/Pseudo-Lab/PhyAI-Lab" alt="Issues Badge"/></a>
<a href="https://github.com/Pseudo-Lab/PhyAI-Lab/graphs/contributors"><img alt="GitHub contributors" src="https://img.shields.io/github/contributors/Pseudo-Lab/PhyAI-Lab?color=2b9348"></a>
</div>
<br>



<!-- sheilds: https://shields.io/ -->
<!-- hits badge: https://hits.seeyoufarm.com/ -->

<p align="center">
  <img src="manipulation2.gif" alt="Demo" width="600"/>
</p>


ğŸš€ **Physical AI Labì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!**\
ì €í¬ëŠ” **`Imitation Learning, Vision-Language-Action(VLA), Robot Reasoning/Planning`** ë“± Physical AIì˜ ìµœì‹  ì—°êµ¬ íë¦„ì„ íƒêµ¬í•©ë‹ˆë‹¤.
ë…¼ë¬¸ ë¦¬ë·°ì™€ í† ë¡ ì„ í†µí•´ íŠ¸ë Œë“œë¥¼ ì´í•´í•˜ê³ , **`ë¡œë´‡ê³¼ ì‹œë®¬ë ˆì´í„°(SO-ARM 101/Isaac Sim)`**
ë¥¼ í™œìš©í•œ ì‹¤í—˜ì„ í†µí•´ í•œê³„ì ê³¼ ê°œì„  ë°©í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤.

ìš°ë¦¬ì˜ ëª©í‘œëŠ” ë¡œë´‡ì´ ì‹¤ìƒí™œì— ë„ì…ë  ìˆ˜ ìˆëŠ” ê¸¸ì„ ì—¬ëŠ” ê²ƒì…ë‹ˆë‹¤.
Physical AIë¥¼ ë” ë˜‘ë˜‘í•˜ê³ , ë” ê°•ë ¥í•˜ë©°, ë” ì‹¤ìš©ì ìœ¼ë¡œ ë§Œë“¤ê¸° ìœ„í•œ ì—¬ì •ì— í•¨ê»˜í•˜ì„¸ìš”!

## ğŸŒŸ í”„ë¡œì íŠ¸ ëª©í‘œ (Project Vision)
- **ë…¼ë¬¸ ë¦¬ë·° ëª©í‘œ**
    - ë§¤ì£¼ í•œ í¸ì˜ ë…¼ë¬¸ì„ ë¦¬ë·°í•˜ë©° Physical AIì˜ ë°œì „ë°©í–¥ì— ëŒ€í•´ ì´í•´
    - Open questionì— ëŒ€í•´ í† ë¡ í•˜ë©° ë¹„íŒì ìœ¼ë¡œ ë…¼ë¬¸ì„ í•´ì„í•˜ê³  ë”ìš± ê¹Šê²Œ ì´í•´í•˜ëŠ” ëŠ¥ë ¥ í•¨ì–‘
- **í”„ë¡œì íŠ¸ ëª©í‘œ**
    - ìµœì‹  ì—°êµ¬ë“¤ì˜ í•œê³„ì ì„ íŒŒì•…í•˜ê³  ì´ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•œ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
    - ì˜ˆì‹œ
        - ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì–´ë–»ê²Œ í‰ê°€í•  ìˆ˜ ìˆìœ¼ë©° ì ì ˆí•œ ë°ì´í„°ì…‹ì„ ì–´ë–»ê²Œ curation í•  ìˆ˜ ìˆì„ê¹Œ?
        - VLAì˜ ì¥ê¸° ë©”ëª¨ë¦¬ ë¶€ì¡± ë¬¸ì œë¥¼ ì–´ë–»ê²Œ í•´ê²°í•  ìˆ˜ ìˆì„ê¹Œ?
        - Teleoperationë§Œìœ¼ë¡œëŠ” LLMì²˜ëŸ¼ internet-scaleì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê¸° ì–´ë ¤ì›€ì„ ì–´ë–»ê²Œ í•´ê²°í•  ê²ƒì¸ê°€?
- **ìµœì¢… ì„±ê³¼ë¬¼**
    - ë…¼ë¬¸ ë¦¬ë·° ì•„ì¹´ì´ë¸Œ
    - ì‹¤í—˜ ê²°ê³¼ ë° ì¸ì‚¬ì´íŠ¸ ì •ë¦¬ â†’ ì¶”í›„ ì—°êµ¬ì£¼ì œ ì„ ì •         |


## ğŸ’» ì£¼ì°¨ë³„ í™œë™ (Activity History)

| ë‚ ì§œ | ì„ ì • ë…¼ë¬¸ | ë°œí‘œì | ë°œí‘œìë£Œ
| -------- | -------- | ---- |------|
| 2025/09/09 | OT       |      |        |
| 2025/09/16 |  [Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware](https://tonyzhaozh.github.io/aloha/)|ê¹€ê²½ì¤€ |  [![Linkedin Badge](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/seong-yun-byeon-8183a8113/)]()
| 2025/09/23 |  Magical Week | - | -
| 2025/09/30 |  ë¯¸ì • | ë¯¸ì • | [![Linkedin Badge](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/seong-yun-byeon-8183a8113/)]()
| 2025/10/7 |  ì¶”ì„ | - |-
| 2025/10/14 |  ë¯¸ì • | ë¯¸ì • | [![Linkedin Badge](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/seong-yun-byeon-8183a8113/)]()
| 2025/10/21 |  ë¯¸ì • | ë¯¸ì • | [![Linkedin Badge](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/seong-yun-byeon-8183a8113/)]()
| 2025/10/28 |  Magical Week |- | -
| 2025/11/04 |  ë¯¸ì • | ë¯¸ì • | [![Linkedin Badge](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/seong-yun-byeon-8183a8113/)]()
| 2025/11/11 | ë¯¸ì • | ë¯¸ì • | [![Linkedin Badge](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/seong-yun-byeon-8183a8113/)]()
| 2025/11/18 | ë¯¸ì • | ë¯¸ì • | [![Linkedin Badge](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/seong-yun-byeon-8183a8113/)]()
| 2025/11/25 |  ë¯¸ì • | ë¯¸ì • | [![Linkedin Badge](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/seong-yun-byeon-8183a8113/)]()
| 2025/12/02 |  ë¯¸ì • | ë¯¸ì • | [![Linkedin Badge](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/seong-yun-byeon-8183a8113/)]()
| 2025/12/09 |  ë¯¸ì • | ë¯¸ì • | [![Linkedin Badge](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/seong-yun-byeon-8183a8113/)]()
| 2025/12/16 |  ë¯¸ì • | ë¯¸ì • | [![Linkedin Badge](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/seong-yun-byeon-8183a8113/)]()
| 2025/12/23 |  ë¯¸ì • | ë¯¸ì • | [![Linkedin Badge](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/seong-yun-byeon-8183a8113/)]()

## ğŸ“šë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
- [Ï€â‚€: A Vision-Language-Action Flow Model for General Robot Control](https://www.physicalintelligence.company/blog/pi0)


- [Gemini Robotics: Bringing AI into the Physical World](https://arxiv.org/abs/2503.20020)
- [FLARE: Robot Learning with Implicit World Modeling](https://research.nvidia.com/labs/gear/flare/)
- [Diffusion-VLA: Generalizable and Interpretable Robot Foundation Model via Self-Generated Reasoning](https://diffusion-vla.github.io/)
- [MimicGen: A Data Generation System for Scalable Robot Learning using Human Demonstrations](https://mimicgen.github.io/) 
- [GR00T N1: An Open Foundation Model for Generalist Humanoid Robots](https://arxiv.org/abs/2503.14734)
- [RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control](https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/)
- [Diffusion Policy: Visuomotor Policy Learning via Action Diffusion](https://diffusion-policy.cs.columbia.edu/)
- [Say Can: Grounding Language in Robotic Affordances](https://say-can.github.io/)
- [OpenVLA:An Open-Source Vision-Language-Action Model](https://openvla.github.io/)
- [ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning](https://arxiv.org/abs/2507.16815)
- [MolmoAct: Action Reasoning Models that can Reason in Space](https://arxiv.org/abs/2508.07917)
- [CoT-VLA: Visual Chain-of-Thought Reasoning for Vision-Language-Action Models](https://cot-vla.github.io/)

### Survey Paper 
- Survey paperë¥¼ ì°¸ê³ í•˜ì—¬ ë°œí‘œë…¼ë¬¸ì„ ì„ ì •í•˜ì…”ë„ ì¢‹ìŠµë‹ˆë‹¤.
- [A Survey on Vision-Language-Action Models for Embodied AI](https://arxiv.org/abs/2405.14093)
- [Vision Language Action Models in Robotic Manipulation: A Systematic Review](https://arxiv.org/abs/2507.10672)



## About Pseudo Lab ğŸ‘‹ğŸ¼</h2>

[Pseudo-Lab](https://pseudo-lab.com/) is a non-profit organization focused on advancing machine learning and AI technologies. Our core values of Sharing, Motivation, and Collaborative Joy drive us to create impactful open-source projects. With over 5k+ researchers, we are committed to advancing machine learning and AI technologies.

<h2>Contributors ğŸ˜ƒ</h2>
<a href="https://github.com/Pseudo-Lab/PhyAI-Lab/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=Pseudo-Lab/PhyAI-Lab" />
</a>
<br><br>

<h2>License ğŸ—</h2>

This project is licensed under the [MIT License](https://opensource.org/licenses/MIT).

